{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import conv2d as libConv2d\n",
    "from torch.nn.functional import conv_transpose2d as libConv2dT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание тензора с исходными данными\n",
    "input_data = torch.randn(1, 1, 2, 2)  # (batch_size, channels, height, width)\n",
    "\n",
    "# Создание тензора с весами (ядром) для транспонированной свертки\n",
    "weights = torch.randn(1, 1, 2, 2)  # (out_channels, in_channels, kernel_height, kernel_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2771,  0.4301,  0.5502],\n",
       "          [ 1.6777, -0.5814,  0.6351],\n",
       "          [-1.5935,  2.7090, -0.7724]]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Применение транспонированной свертки\n",
    "output = libConv2dT(input_data, weights, stride=1, padding=0, dilation=1)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 1\n",
    "padding = 0\n",
    "dilattion = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.3021, -1.0841],\n",
       "          [ 1.5359, -2.0545]]]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2128, -0.5075],\n",
       "          [-1.0375,  0.3759]]]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_transposed(\n",
    "    matrix, in_channels, out_channels, kernel_size,\n",
    "    stride=1, padding=0, output_padding=0, dilation=1,\n",
    "    bias=True, padding_mode='zeros'\n",
    "):\n",
    "\n",
    "    #генерация bias\n",
    "    if bias == True:\n",
    "      bias_val = torch.rand(out_channels)\n",
    "    else:\n",
    "      bias_val = torch.zeros(out_channels)\n",
    "\n",
    "    #padding_mode\n",
    "    if (padding_mode != 'zeros'):\n",
    "      raise ValueError('only \"zeros\" padding_mode in ConvTranspose2d')\n",
    "\n",
    "    #генерация ядра\n",
    "    if type(kernel_size) == tuple:\n",
    "      weights = torch.rand(in_channels, out_channels, kernel_size[0], kernel_size[1])\n",
    "    if type(kernel_size) == int:\n",
    "      weights = torch.rand(in_channels, out_channels, kernel_size, kernel_size)\n",
    "\n",
    "    res_tensor = []\n",
    "\n",
    "    for l in range(out_channels):\n",
    "\n",
    "      feature_map = torch.zeros((matrix.shape[1]-1)*stride + dilation * (kernel_size-1)+1, (matrix.shape[2]-1)*stride  + dilation * (kernel_size-1)+1 ) #генерация пустой feature-map\n",
    "      for c in range (in_channels):\n",
    "\n",
    "        for i in range (0, matrix.shape[1]):  #проход по всем пикселям изображения\n",
    "          for j in range (0, matrix.shape[2]):\n",
    "\n",
    "            val = matrix[c][i][j]\n",
    "            proizv = val*weights[c][l]\n",
    "\n",
    "            zero_tensor = torch.zeros((weights.shape[2]-1)*dilation+1, (weights.shape[3]-1)*dilation+1)\n",
    "\n",
    "            for a in range (0, zero_tensor.shape[0], dilation):\n",
    "              for b in range (0, zero_tensor.shape[1], dilation):\n",
    "                zero_tensor[a][b] = proizv[a//dilation][b//dilation]\n",
    "\n",
    "            res = np.add((zero_tensor), feature_map[i*stride:i*stride+(weights.shape[2]-1)*dilation+1, j*stride:j*stride+(weights.shape[3]-1)*dilation+1])\n",
    "            feature_map[i*stride:i*stride+(weights.shape[2]-1)*dilation+1, j*stride:j*stride+(weights.shape[3]-1)*dilation+1] = res\n",
    "\n",
    "\n",
    "      res_tensor.append(np.add(feature_map, np.full((feature_map.shape), bias_val[l])))\n",
    "\n",
    "\n",
    "    for t in range(len(res_tensor)):\n",
    "      if output_padding > 0:\n",
    "        pad_func = torch.nn.ConstantPad1d((0, output_padding, 0, output_padding), 0)\n",
    "        res_tensor[t] = pad_func(res_tensor[t])\n",
    "\n",
    "      res_tensor[t] = res_tensor[t][0+padding:res_tensor[t].shape[0]-padding, 0+padding:res_tensor[t].shape[1]-padding]\n",
    "\n",
    "\n",
    "    return res_tensor, weights, torch.tensor(bias_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(tensor, in_channels, out_channels, kernel_size, stride, padding, output_padding, dilation, bias=True, padding_mode='zeros'):\n",
    "    myres, kernel, bias_val = conv2d_transposed(\n",
    "        tensor,\n",
    "        in_channels=in_channels, out_channels=out_channels, \n",
    "        kernel_size=kernel_size, stride=stride,\n",
    "        padding=padding, output_padding=output_padding,\n",
    "        dilation=dilation, bias=bias,\n",
    "        padding_mode=padding_mode,\n",
    "        )\n",
    "    torchFunction = torch.nn.ConvTranspose2d(\n",
    "        in_channels=in_channels, out_channels=out_channels,\n",
    "        kernel_size=kernel_size, stride=stride, \n",
    "        padding=padding, output_padding=output_padding,\n",
    "        dilation=dilation, bias=bias, \n",
    "        padding_mode=padding_mode,\n",
    "        )\n",
    "    torchFunction.weight.data = kernel\n",
    "    torchFunction.bias.data = bias_val\n",
    "\n",
    "    result = str(np.round([tensor.tolist() for tensor in myres],2))\n",
    "    torch_res = str(np.round(torchFunction(tensor).data.numpy(),2))\n",
    "    print(result==torch_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.rand(8, 5, 6)\n",
    "tensor2 = torch.rand(3, 28, 28)\n",
    "tensor3 = torch.rand(5, 6, 6)\n",
    "tensor4 = torch.rand(1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vexrina\\AppData\\Local\\Temp\\ipykernel_7056\\1286083728.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return res_tensor, weights, torch.tensor(bias_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "compare(tensor1, in_channels=8, out_channels=2, kernel_size=3, stride=1, padding=0, output_padding=0, dilation=1, bias=True, padding_mode='zeros')\n",
    "compare(tensor2, in_channels=3, out_channels=2, kernel_size=3, stride=10, padding=0, output_padding=0, dilation=3, bias=True, padding_mode='zeros')\n",
    "compare(tensor3, in_channels=5, out_channels=1, kernel_size=3, stride=3, padding=5, output_padding=2, dilation=1, bias=True, padding_mode='zeros')\n",
    "compare(tensor4, in_channels=1, out_channels=1, kernel_size=1, stride=1, padding=0, output_padding=0, dilation=1, bias=True, padding_mode='zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cooler_transpconv2d(\n",
    "  input, in_channels, out_channels, kernel_size,\n",
    "  transp_stride=1, padding=0, dilation=1, bias=True,\n",
    "  padding_mode='zeros' \n",
    "):\n",
    "  stride = 1\n",
    "  \n",
    "  pad = kernel_size - 1\n",
    "  result_input = []\n",
    "  for matr in input:\n",
    "    zero_tensor = np.zeros((((matr.shape[0]-1)*(transp_stride)+1), ((matr.shape[1]-1)*(transp_stride)+1)))\n",
    "    for a in range (0, zero_tensor.shape[0], transp_stride):\n",
    "      for b in range (0, zero_tensor.shape[1], transp_stride):\n",
    "        zero_tensor[a][b] = matr[a//(transp_stride)][b//(transp_stride)]\n",
    "\n",
    "    pad_matr = np.pad(zero_tensor, pad_width=pad, mode='constant')\n",
    "    result_input.append(pad_matr)\n",
    "  input = torch.tensor(result_input)\n",
    "  if bias == True:\n",
    "    bias_val = torch.rand(out_channels)\n",
    "  else:\n",
    "    bias_val = torch.zeros(out_channels)\n",
    "    \n",
    "  if (padding_mode == 'zeros'):\n",
    "    pad = torch.nn.ZeroPad2d(padding)\n",
    "    input = pad(input)\n",
    "  if (padding_mode == 'reflect'):\n",
    "    pad = torch.nn.ReflectionPad2d(padding)\n",
    "    input = pad(input)\n",
    "  if (padding_mode == 'replicate'):\n",
    "    pad = torch.nn.ReplicationPad2d(padding)\n",
    "    input = pad(input)\n",
    "  if (padding_mode == 'circular'):\n",
    "    pad = torch.nn.CircularPad2d(padding)\n",
    "    input = pad(input)\n",
    "\n",
    "  weights = np.array(torch.rand(out_channels, in_channels, kernel_size, kernel_size))\n",
    "\n",
    "  weights_for_transpose = []\n",
    "  for j in range(out_channels):\n",
    "    weights_in = []\n",
    "    for i in range(in_channels):\n",
    "      weights_in.append(np.flip(np.array(weights[j][i])))\n",
    "    weights_for_transpose.append(weights_in)\n",
    "\n",
    "  weights_for_transpose = torch.tensor(weights_for_transpose)\n",
    "  weights_for_transpose = weights_for_transpose.reshape(in_channels, out_channels, kernel_size, kernel_size)\n",
    "\n",
    "\n",
    "\n",
    "  res_tensor = []\n",
    "  for l in range(out_channels):\n",
    "    feature_map = np.array([])\n",
    "    for i in range (0, input.shape[1]-((weights.shape[2]-1)*dilation+1)+1, stride):\n",
    "      for j in range (0, input.shape[2]-((weights.shape[3]-1)*dilation+1)+1, stride):\n",
    "        summa = 0\n",
    "        for c in range (in_channels):\n",
    "          val = input[c][i:i+(weights.shape[2]-1)*dilation+1:dilation, j:j+(weights.shape[3]-1)*dilation+1:dilation]\n",
    "          mini_sum = (val*weights[l][c]).sum()\n",
    "          summa = summa + mini_sum\n",
    "        feature_map = np.append(feature_map, float(summa + bias_val[l]))\n",
    "    res_tensor.append(feature_map.reshape((input.shape[1]-((weights.shape[2]-1)*dilation+1))//stride+1, (input.shape[2]-((weights.shape[3]-1)*dilation+1))//stride+1))\n",
    "\n",
    "\n",
    "  return np.array(res_tensor), torch.tensor(np.array(weights_for_transpose)), torch.tensor(np.array(bias_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cooler_compare(tensor, in_channels, out_channels, kernel_size, stride, transp_stride, bias=True,):\n",
    "    myres, kernel, bias_val = cooler_transpconv2d(\n",
    "        tensor,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels, \n",
    "        kernel_size=kernel_size, \n",
    "        transp_stride=transp_stride, \n",
    "        bias=bias,\n",
    "        )\n",
    "    torchFunction = torch.nn.ConvTranspose2d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=kernel_size,\n",
    "        stride=stride,\n",
    "        bias=bias,\n",
    "        )\n",
    "    torchFunction.weight.data = kernel\n",
    "    torchFunction.bias.data = bias_val\n",
    "\n",
    "    result = str(np.round(myres, 2))\n",
    "    torch_res = str(np.round(torchFunction(tensor).data.numpy(),2))\n",
    "    print(result==torch_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.rand(3, 5, 6)\n",
    "tensor2 = torch.rand(1, 28, 28)\n",
    "tensor3 = torch.rand(7, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cooler_compare(tensor1, 3,1,3,2,2,True)\n",
    "cooler_compare(tensor2, 1,2,4,3,3,True)\n",
    "cooler_compare(tensor3, 7,1,3,5,5,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
